<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.79.0"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta property="og:title" content="Here’s how OpenAI’s magical DALL-E image generator works"><meta name=author content="Tech - The Next Web"><meta name=keywords content="Tech-The-Next-Web"><meta property="og:title" content="Here’s how OpenAI’s magical DALL-E image generator works"><meta property="og:description" content="It seems like every few months, someone publishes a machine learning paper or demo that makes my jaw drop. This month, it’s OpenAI’s new image-generating model, DALL·E. This behemoth 12-billion-parameter neural network takes a text caption (i.e. “an armchair in the shape of an avocado”) and generates images to match it: I think its pictures are pretty inspiring (I’d buy one of those avocado chairs), but what’s even more impressive is DALL·E’s ability to understand and render concepts of space, time, and even logic (more on that in a second)."><meta property="og:type" content="article"><meta property="og:url" content="https://news.panz3r.dev/post/6b36ea0f6f5a01ebc17081e1ebddc3a9c25a18256b9973f0b0348d7622892e2c/"><meta property="article:published_time" content="2021-01-10T11:00:59+00:00"><meta property="article:modified_time" content="2021-01-10T11:00:59+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Here’s how OpenAI’s magical DALL-E image generator works"><meta name=twitter:description content="It seems like every few months, someone publishes a machine learning paper or demo that makes my jaw drop. This month, it’s OpenAI’s new image-generating model, DALL·E. This behemoth 12-billion-parameter neural network takes a text caption (i.e. “an armchair in the shape of an avocado”) and generates images to match it: I think its pictures are pretty inspiring (I’d buy one of those avocado chairs), but what’s even more impressive is DALL·E’s ability to understand and render concepts of space, time, and even logic (more on that in a second)."><link rel="shortcut icon" href=/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=mask-icon color=#8a0000 href=/safari-pinned-tab.svg><meta name=msapplication-TileColor content="#8A0000"><link rel=stylesheet type=text/css media=screen href=/css/normalize.min.15dd2454cf02be612cd84be5a0307ecae7e9c84d08f88ab2d1e9332717d10fe9b63484bb4c5352072da0915d1a6d48fa41994fb99c120c891cca431b4448f44d.css integrity="sha512-Fd0kVM8CvmEs2EvloDB+yufpyE0I+Iqy0ekzJxfRD+m2NIS7TFNSBy2gkV0abUj6QZlPuZwSDIkcykMbREj0TQ=="><link rel=stylesheet type=text/css media=screen href=/css/main.min.213824d03b199f0409b76c8566e3f3e4fbbe8f03c184b43a665128ee2120bbf3704a1d62249e92ad27ba4c158e21f02299e52148b06efa51a5e54824bfdf6f95.css integrity="sha512-ITgk0DsZnwQJt2yFZuPz5Pu+jwPBhLQ6ZlEo7iEgu/NwSh1iJJ6SrSe6TBWOIfAimeUhSLBu+lGl5Ugkv99vlQ=="><link rel=stylesheet type=text/css media=screen href=/css/all.min.110b9b90a76992e589133569a74d7933787d3b97d05cb148bac6c44edaa09afb226b6bd200c52f9efbe30eaecffc11b244d8ed8109b46bb490cd09109656509c.css integrity="sha512-EQubkKdpkuWJEzVpp015M3h9O5fQXLFIusbETtqgmvsia2vSAMUvnvvjDq7P/BGyRNjtgQm0a7SQzQkQllZQnA=="><title>Here’s how OpenAI’s magical DALL-E image generator works | Panz3r News</title></head><body><header><div id=titletext><h2 id=title><a href=https://news.panz3r.dev/>Panz3r News</a></h2></div><div id=title-description><div id=social><nav><ul><li><a href=https://github.com/panz3r/news-feed><i title=Github class="icons fab fa-github"></i></a></li><li><a href=/index.xml><i title=RSS class="icons fas fa-rss"></i></a></li></ul></nav></div></div><div id=mainmenu><nav><ul><li><a href=/>Home</a></li><li><a href=/tags>Tags</a></li></ul></nav></div></header><main><div class=post><div class=author><p>From <a href=https://thenextweb.com/neural/2021/01/10/heres-how-openais-magical-dall-e-generates-images-from-text-syndication/ target=_blank rel="noopener noreferrer">Tech - The Next Web</a></p></div><div class=post-header><div class=meta><div class=date><span class=day>10</span>
<span class=rest>Jan 2021</span></div></div><div class=matter><h1 class=title>Here’s how OpenAI’s magical DALL-E image generator works</h1></div></div><div class=markdown><p><img src=https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/01/1-copy-13-796x417.jpg width=796 height=417><br>It seems like every few months, someone publishes a machine learning paper or demo that makes my jaw drop. This month, it’s OpenAI’s new image-generating model, DALL·E. This behemoth 12-billion-parameter neural network takes a text caption (i.e. “an armchair in the shape of an avocado”) and generates images to match it: I think its pictures are pretty inspiring (I’d buy one of those avocado chairs), but what’s even more impressive is DALL·E’s ability to understand and render concepts of space, time, and even logic (more on that in a second). In this post, I’ll give you a quick overview of what…<br><br><a href="https://thenextweb.com/neural/2021/01/10/heres-how-openais-magical-dall-e-generates-images-from-text-syndication/?utm_source=social&utm_medium=feed&utm_campaign=profeed">This story continues</a> at The Next Web</p></div><div class=tags><div class=taxosfloating_left><p>Tags</p></div><div class=termsfloating_right><p><a href=/tags/tech-the-next-web/>tech-the-next-web</a></p></div><div class=clearit></div></div></div></main><footer><a href=https://github.com/panz3r>Panz3r</a> 2020 | <a href=https://github.com/panz3r/hugo-vitae>Vitae</a> theme for <a href=https://gohugo.io>Hugo</a></footer></body></html>